{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "\n",
    "from model.vae import VAE, CVAE, CVAE_su\n",
    "from model.loss import VAE_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化wandb项目\n",
    "wandb.init(project=\"VAE2\")\n",
    "# pytorch minst数据集\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,)) \n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置主要参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 512\n",
    "kernel_size = 3\n",
    "filters     = 16\n",
    "epochs      = 30\n",
    "latent_dim  = 2   ## 隐变量取2维只是为了方便后面画图，适当提高可以提高生成质量，比如提高到8\n",
    "device      = 1   ## 选取gpu，这里选择了第一个gpu\n",
    "num_classes = 10  \n",
    "image_size  = train_dataset[0][0].shape[1] ## 1 * 28 * 28\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = CVAE_su(filters, kernel_size, latent_dim, image_size)\n",
    "# vaeloss = VAE_loss()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "vae.to(device)\n",
    "vae.train()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    for i, (x,y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        x_recon, mu, logvar, loss = vae(x, y)\n",
    "        recon_loss, kl_div = loss\n",
    "        loss = recon_loss + kl_div\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({\"iter\": i, \"reconstruction_loss\": recon_loss.item(), \"kl_divergence\": kl_div.item()}, commit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vae.eval()\n",
    "for x_test, y_test in test_loader:\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "    x_recon, mu, logvar, loss = vae(x_test, y_test)\n",
    "    break\n",
    "\n",
    "original_images = x_test *std + mean\n",
    "generated_images = x_recon\n",
    "\n",
    "comparison_grid = torch.cat((original_images, generated_images), dim=2)\n",
    "grid = make_grid(comparison_grid, nrow=40, padding=2).cpu()\n",
    "\n",
    "# 展示结果，第一行是原图，第二行是生成图，以此类推\n",
    "torchvision.transforms.ToPILImage()(grid).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示每个数字类别与latent向量的关系(当latent=2时)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "for x_test, y_test in test_loader:\n",
    "    x_test = x_test.to(device)\n",
    "    mu, logvar = vae.encoder(x_test)\n",
    "    z = vae.reparameterize(mu, logvar).cpu().detach().numpy()\n",
    "    break\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(z[:, 0], z[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla VAE show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# 观察隐变量的两个维度变化是如何影响输出结果的\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "#用正态分布的分位数来构建隐变量对\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "with torch.no_grad():\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder(torch.from_numpy(z_sample).to(device).float())\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size).cpu()\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVAE show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 观察隐变量的两个维度变化是如何影响输出结果的\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "target = 9 ## 生成数字9的图片\n",
    "#用正态分布的分位数来构建隐变量对\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "with torch.no_grad():\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = torch.from_numpy(np.array([[xi, yi]])).to(device).float() ## 1*2\n",
    "            y = torch.tensor([target]).to(device)  ## 1*1\n",
    "            y = F.one_hot(y, num_classes=num_classes).float() ## 1*num_classes\n",
    "            z = torch.cat([z_sample, y], dim=1)\n",
    "            x_decoded = vae.decoder(z)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size).cpu()\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVAE_su show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 观察隐变量的两个维度变化是如何影响输出结果的\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "target = 9 ## 生成数字9的图片\n",
    "class_mu = vae.encoder_class(torch.eye(num_classes).to(device).float())\n",
    "class_mu = class_mu.cpu().detach().numpy()\n",
    "#用正态分布的分位数来构建隐变量对\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n)) + class_mu[target][0]\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n)) + class_mu[target][1]\n",
    "with torch.no_grad():\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z = torch.from_numpy(np.array([[xi, yi]])).to(device).float() ## 1*2\n",
    "            # y = torch.tensor([target]).to(device)  ## 1*1\n",
    "            # y = F.one_hot(y, num_classes=num_classes).float() ## 1*num_classes\n",
    "            # z = torch.cat([z_sample, y], dim=1)\n",
    "            x_decoded = vae.decoder(z)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size).cpu()\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-Lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
